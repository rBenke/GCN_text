{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from models import GCN\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "\n",
    "# Set random seed\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths to available grahs metadata\n",
    "N_sample = 200000\n",
    "adj_mat, features_mat, train_labels_mat, test_labels_mat, val_labels_mat, train_mask_mat, test_mask_mat, val_mask_mat = load_data(\"txt_graph2216_21012020\", N_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(465542, 465542)\n",
      "(465542, 100)\n",
      "(465542, 5)\n",
      "(465542, 5)\n",
      "(465542, 5)\n",
      "(465542, 5)\n",
      "(465542, 5)\n",
      "(465542, 5)\n",
      "number of masked elements\n",
      "train: 779\n",
      "test: 668\n",
      "val: 778\n",
      "\n",
      " positions of ones in masked labels\n",
      "[2 1 0 4 0 4 4 1 3 0 3 3 0 4 2 0 0 1 4 1 1 3 0 2 0 1 1 0 4 0 4 3 3 2 2 0 2\n",
      " 2 4 4 1 3 2 2 0 4 4 4 3 1 2 0 3 1 2 0 1 3 4 0 3 3 3 4 0 1 4 1 3 4 3 1 1 1\n",
      " 3 0 0 4 3 2 1 0 0 0 2 0 4 3 0 0 4 4 3 2 3 3 1 4 3 4 1 0 3 2 4 3 4 4 0 1 4\n",
      " 3 1 0 1 3 3 4 4 3 3 3 4 3 2 3 1 2 3 1 3 0 2 0 3 2 4 2 0 2 0 4 2 0 2 1 0 2\n",
      " 0 0 3 0 1 2 3 3 3 1 4 3 2 4 3 3 0 4 3 1 3 1 3 0 4 2 4 2 0 3 2 3 2 2 2 0 2\n",
      " 2 4 0 2 3 0 2 0 0 0 2 0 0 2 2 2 3 2 0 3 1 4 3 0 0 4 1 2 2 4 0 2 3 0 4 2 3\n",
      " 0 0 2 1 0 0 3 3 3 1 2 4 0 3 0 3 3 1 4 3 2 4 2 3 4 0 3 4 0 3 3 4 0 0 0 3 3\n",
      " 0 2 1 4 4 3 0 0 4 4 1 1 4 3 0 3 4 3 2 3 2 1 4 3 4 0 3 0 4 4 0 4 1 2 2 3 3\n",
      " 3 0 2 4 3 3 2 3 4 2 1 0 2 4 4 1 4 3 4 3 1 3 3 1 3 2 0 4 1 0 2 3 0 4 4 4 1\n",
      " 3 3 4 1 0 4 2 3 3 0 0 1 2 3 1 0 4 0 2 3 1 1 0 2 3 3 1 0 4 3 3 2 4 0 0 1 1\n",
      " 0 0 0 2 0 0 3 3 4 3 1 1 0 4 2 1 0 0 3 1 4 1 3 0 3 1 2 4 3 3 4 1 4 2 0 2 1\n",
      " 4 3 3 2 4 0 0 1 1 2 0 2 2 0 3 0 3 3 2 0 1 4 2 0 2 1 3 0 4 0 0 0 4 3 0 2 0\n",
      " 2 3 0 3 4 4 1 0 1 4 1 2 3 4 3 0 1 2 3 4 2 4 3 2 2 0 4 2 0 3 4 3 3 3 2 4 2\n",
      " 1 4 4 0 3 2 2 1 0 1 4 3 2 1 1 3 0 2 2 0 2 3 2 3 1 0 1 3 1 4 0 0 4 4 0 0 0\n",
      " 0 2 3 3 1 1 2 0 0 3 2 4 4 2 3 1 0 2 0 3 2 4 2 1 0 3 4 1 1 4 2 3 1 3 3 1 4\n",
      " 1 3 4 2 2 2 2 3 0 2 3 3 4 0 4 0 2 4 0 4 0 0 3 4 0 4 0 3 4 3 3 1 4 0 4 4 3\n",
      " 3 3 3 1 1 2 0 2 3 3 2 3 3 4 1 0 2 3 0 1 4 1 0 1 2 0 2 1 1 0 4 3 4 3 4 3 3\n",
      " 0 2 0 0 1 1 3 1 1 0 1 1 3 3 0 3 1 2 3 4 2 4 4 4 3 3 0 3 0 3 4 4 2 0 4 3 3\n",
      " 0 3 1 0 1 0 0 0 4 0 3 3 2 4 3 3 4 1 0 0 0 0 0 3 2 3 4 0 3 3 0 4 1 2 1 0 2\n",
      " 1 1 0 0 2 3 2 1 3 3 3 0 1 3 0 0 2 3 2 1 0 4 3 0 2 1 4 0 4 3 0 4 4 2 0 4 4\n",
      " 0 3 2 2 0 1 4 4 2 4 2 0 3 3 0 3 1 2 4 0 4 1 2 2 2 0 2 0 0 4 4 4 2 3 1 1 4\n",
      " 1 1]\n",
      "[0 2 3 4 1 3 4 4 0 4 2 0 4 2 1 3 3 0 0 3 2 3 2 2 4 3 0 0 2 0 0 3 3 3 3 2 3\n",
      " 2 2 1 2 4 4 2 0 3 2 4 0 3 3 4 2 3 4 3 3 4 2 2 4 3 4 0 3 4 2 4 2 3 0 4 2 2\n",
      " 3 0 1 1 1 3 0 1 0 0 0 3 3 0 2 4 4 2 3 1 3 3 2 0 1 0 2 3 0 0 2 1 2 3 1 1 4\n",
      " 4 0 0 0 1 2 3 0 0 4 1 3 3 1 1 3 2 3 2 0 3 4 1 0 4 3 0 1 4 2 3 2 1 2 3 1 3\n",
      " 0 0 3 2 1 3 0 3 2 3 3 2 1 4 1 3 4 1 0 4 1 2 4 4 4 1 0 1 1 0 0 4 2 3 1 0 2\n",
      " 3 0 1 3 0 1 4 4 0 3 1 2 2 4 1 4 3 1 4 0 2 1 3 2 4 0 0 3 4 0 3 0 0 4 3 3 1\n",
      " 2 4 1 3 4 4 2 3 0 3 3 1 2 1 3 1 4 2 2 2 4 1 1 2 2 3 3 3 3 0 2 2 3 2 1 1 3\n",
      " 2 4 1 1 3 3 0 2 4 1 2 1 3 1 1 0 3 1 0 1 1 3 2 0 3 1 0 3 4 1 1 4 3 0 3 2 2\n",
      " 2 2 4 0 0 2 4 3 2 4 4 1 2 0 3 1 2 3 4 1 1 3 4 4 3 2 3 0 0 3 4 0 1 3 2 4 4\n",
      " 1 0 1 1 0 2 2 2 2 4 3 2 3 2 3 3 4 0 3 2 1 0 4 2 0 0 3 0 0 3 3 2 2 0 1 1 3\n",
      " 0 4 0 4 1 0 4 0 1 1 0 0 3 1 3 4 4 3 1 0 3 0 3 1 3 3 3 1 0 3 4 2 4 3 1 2 0\n",
      " 2 3 3 4 3 0 1 1 2 3 3 4 1 3 1 1 3 1 4 0 1 1 2 4 0 3 1 0 1 2 1 1 0 1 1 3 3\n",
      " 2 4 1 2 2 4 4 0 0 2 3 3 2 3 2 3 4 2 0 2 3 0 3 1 2 2 1 3 4 4 3 1 3 2 1 1 2\n",
      " 4 0 4 3 1 3 0 4 0 4 4 0 3 4 0 2 0 1 3 1 4 4 2 3 1 0 3 4 2 2 4 4 4 0 4 3 1\n",
      " 1 4 2 0 2 1 2 3 3 4 2 0 0 0 3 2 2 1 1 0 3 2 2 0 1 3 2 4 2 4 4 3 2 0 1 1 4\n",
      " 3 3 4 3 2 0 0 0 1 4 3 2 2 0 4 1 3 1 0 3 1 2 2 1 3 1 3 4 0 4 4 1 3 3 2 0 2\n",
      " 2 2 0 1 0 0 4 3 4 3 0 0 3 2 3 4 4 3 2 0 4 1 0 0 2 3 2 1 2 4 2 3 0 2 2 3 2\n",
      " 3 4 3 1 0 2 1 0 3 2 2 0 0 3 3 0 3 2 1 2 1 4 2 1 2 1 2 3 3 3 3 2 3 0 0 0 1\n",
      " 2 2]\n",
      "[3 0 2 2 4 3 1 2 2 3 0 2 4 2 4 4 0 0 3 3 0 0 1 4 4 1 2 1 2 3 1 0 4 4 2 2 3\n",
      " 2 1 0 1 1 3 4 0 1 0 2 1 2 3 4 0 0 1 4 1 0 4 2 0 3 3 1 3 1 3 4 0 3 3 0 1 3\n",
      " 3 2 3 3 2 1 2 0 0 1 1 1 3 0 3 3 3 0 3 1 1 1 4 4 3 4 1 0 0 3 2 4 4 0 4 3 2\n",
      " 0 3 2 0 2 2 3 1 4 4 4 4 0 3 3 0 4 2 4 1 4 4 4 2 3 2 1 4 0 1 4 3 0 1 1 1 0\n",
      " 4 0 2 2 3 1 1 3 0 1 0 2 0 2 2 3 2 3 2 0 0 1 2 2 2 0 0 0 0 2 3 3 1 0 0 4 0\n",
      " 4 4 0 0 4 1 1 0 1 3 4 0 0 3 4 3 3 0 4 1 4 0 0 3 2 1 2 3 3 3 3 3 1 0 3 2 0\n",
      " 3 0 1 1 4 0 0 3 0 3 0 0 1 4 4 1 4 2 0 2 4 4 1 3 0 4 2 4 0 0 1 4 4 4 0 0 0\n",
      " 2 0 0 4 4 4 3 1 2 0 2 3 0 1 1 1 2 3 3 0 0 1 3 1 4 4 3 0 0 0 2 4 3 3 1 2 0\n",
      " 4 3 1 3 0 3 3 0 4 1 4 1 1 2 0 0 4 0 0 0 4 2 1 1 1 0 2 0 1 0 4 0 3 2 1 3 0\n",
      " 4 2 3 0 0 0 3 3 3 3 4 4 1 1 0 0 0 0 4 4 2 3 1 2 0 1 1 2 2 0 1 1 0 3 3 1 1\n",
      " 0 3 4 4 3 0 0 2 1 1 3 0 0 2 1 0 0 4 4 3 3 2 0 2 2 3 3 4 2 4 4 3 4 3 3 4 3\n",
      " 2 1 1 3 4 1 1 2 1 3 2 2 0 0 2 2 0 4 1 0 4 1 2 2 3 4 3 1 3 4 3 2 1 1 1 1 3\n",
      " 0 0 3 0 0 0 3 0 0 2 2 3 0 4 1 2 2 3 3 3 2 1 3 0 0 3 0 2 0 1 0 0 4 3 4 4 4\n",
      " 0 1 2 2 4 2 3 2 4 0 2 0 1 3 3 4 0 2 1 2 0 2 1 4 0 3 4 2 4 4 0 0 1 0 0 3 2\n",
      " 0 4 4 4 3 3 2 1 2 1 1 1 0 4 2 1 3 0 1 4 1 0 3 2 4 1 2 3 1 3 0 0 2 0 3 4 4\n",
      " 1 3 3 1 0 3 3 4 0 3 3 4 0 2 0 1 0 0 1 4 0 2 2 3 2 2 1 4 0 4 3 1 3 0 0 3 4\n",
      " 4 4 2 2 2 1 0 1 3 3 2 4 0 0 3 3 0 4 4 2 0 2 0 2 2 3 2 0 0 4 4 2 0 0 2 3 2\n",
      " 1 0 2 0 4 2 3 0 2 4 2 1 1 0 0 2 0 1 4 4 4 0 3 1 4 1 4 1 2 2 1 3 1 1 1 3 1\n",
      " 0 2 0 3 2 1 0 0 2 0 3 0 3 1 1 0 3 3 1 4 0 0 3 2 1 2 3 1 1 2 3 4 0 3 0 3 3\n",
      " 2 1 2 0 4 3 0 3 4 2 2 0 0 3 1 0 4 4 2 0 1 4 4 1 4 4 3 4 0 3 0 0 2 2 1 1 4\n",
      " 4 2 3 4 2 3 2 4 3 3 3 0 1 0 3 2 0 4 0 0 1 1 4 0 4 0 1 2 0 1 2 4 2 0 2 0 3\n",
      " 2]\n",
      "\n",
      " ones outside the mask\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "(array([], dtype=int64), array([], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(adj_mat.shape)\n",
    "print(features_mat.shape)\n",
    "print(train_labels_mat.shape)\n",
    "print(test_labels_mat.shape)\n",
    "print(val_labels_mat.shape)\n",
    "print(train_mask_mat.shape)\n",
    "print(test_mask_mat.shape)\n",
    "print(val_mask_mat.shape)\n",
    "\n",
    "print(\"number of masked elements\")\n",
    "print(\"train: \" + str(len(np.where(train_mask_mat[:,1]==1)[0])))\n",
    "print(\"test: \" + str(len(np.where(test_mask_mat[:,1]==1)[0])))\n",
    "print(\"val: \" + str(len(np.where(val_mask_mat[:,1]==1)[0])))\n",
    "\n",
    "print(\"\\n positions of ones in masked labels\")\n",
    "print(np.where(train_labels_mat[np.array(train_mask_mat[:,1],dtype=bool)]==1)[1])\n",
    "print(np.where(test_labels_mat[np.array(test_mask_mat[:,1],dtype=bool)]==1)[1])\n",
    "print(np.where(val_labels_mat[np.array(val_mask_mat[:,1],dtype=bool)]==1)[1])\n",
    "\n",
    "print(\"\\n ones outside the mask\")\n",
    "print(np.where(train_labels_mat[np.logical_not(np.array(train_mask_mat[:,1],dtype=bool))]==1))\n",
    "print(np.where(test_labels_mat[np.logical_not(np.array(test_mask_mat[:,1],dtype=bool))]==1))\n",
    "print(np.where(val_labels_mat[np.logical_not(np.array(val_mask_mat[:,1],dtype=bool))]==1))\n",
    "\n",
    "#sum_global_nodes = np.sum(adj_mat.toarray()[:,np.array(train_mask_mat[:,1],dtype=bool)], axis = 1) + np.sum(adj_mat.toarray()[:,np.array(test_mask_mat[:,1],dtype=bool)], axis = 1) + np.sum(adj_mat.toarray()[:,np.array(val_mask_mat[:,1],dtype=bool)], axis = 1)\n",
    "#print(adj_mat.shape[1] - sum(sum_global_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robertb/python/GCN_text_classif/gcn/utils.py:57: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n"
     ]
    }
   ],
   "source": [
    "#delete all flags before declaration new one\n",
    "del_all_flags(tf.flags.FLAGS)\n",
    "\n",
    "# Settings\n",
    "flags = tf.app.flags\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('mode', '', 'kernel') # for line by line mode\n",
    "tf.app.flags.DEFINE_string('port', '', 'kernel') # for line by line mode\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel') # for jupyter notebook\n",
    "\n",
    "flags.DEFINE_float('learning_rate', 0.03, 'Initial learning rate.') #0.01\n",
    "flags.DEFINE_integer('epochs', 200, 'Number of epochs to train.') #200\n",
    "flags.DEFINE_integer('hidden1', 64, 'Number of units in hidden layer 1.') #16\n",
    "flags.DEFINE_float('dropout', 0.6, 'Dropout rate (1 - keep probability).') #0.5\n",
    "flags.DEFINE_float('weight_decay', 5e-4, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_integer('early_stopping', 20, 'Tolerance for early stopping (# of epochs).') #10\n",
    "\n",
    "# Some preprocessing\n",
    "features = preprocess_features(features_mat)\n",
    "support = [preprocess_adj(adj_mat)]\n",
    "num_supports = 1\n",
    "model_func = GCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/robertb/python/GCN_text_classif/gcn/models.py:95: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/robertb/python/GCN_text_classif/gcn/models.py:40: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/robertb/.pyenv/versions/graph/lib/python3.6/site-packages/gcn-1.0-py3.6.egg/gcn/inits.py:14: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/robertb/.pyenv/versions/graph/lib/python3.6/site-packages/gcn-1.0-py3.6.egg/gcn/layers.py:82: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/robertb/.pyenv/versions/graph/lib/python3.6/site-packages/gcn-1.0-py3.6.egg/gcn/layers.py:26: The name tf.sparse_retain is deprecated. Please use tf.sparse.retain instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/robertb/.pyenv/versions/graph/lib/python3.6/site-packages/gcn-1.0-py3.6.egg/gcn/layers.py:33: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/robertb/.pyenv/versions/graph/lib/python3.6/site-packages/gcn-1.0-py3.6.egg/gcn/layers.py:170: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/robertb/python/GCN_text_classif/gcn/models.py:51: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/robertb/python/GCN_text_classif/gcn/models.py:51: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/robertb/.pyenv/versions/graph/lib/python3.6/site-packages/gcn-1.0-py3.6.egg/gcn/metrics.py:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define placeholders\n",
    "placeholders = {\n",
    "    'support': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n",
    "    'labels': tf.placeholder(tf.float32, shape=(None, train_labels_mat.shape[1])),\n",
    "    'labels_mask': tf.placeholder(tf.int32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    'num_features_nonzero': tf.placeholder(tf.int32)  # helper variable for sparse dropout\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = model_func(placeholders, input_dim=features[2][1], logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "# Init variables\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "cost_val = []\n",
    "\n",
    "for epoch in range(FLAGS.epochs):\n",
    "\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(features, support, train_labels_mat, train_mask_mat[:,1], placeholders)\n",
    "    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "\n",
    "    # Training step\n",
    "    outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "\n",
    "    # Validation\n",
    "    cost, acc, duration = evaluate(features, support, val_labels_mat, val_mask_mat[:,1], placeholders, sess, model)\n",
    "    cost_val.append(cost)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "          \"train_acc=\", \"{:.5f}\".format(outs[2]), \"val_loss=\", \"{:.5f}\".format(cost),\n",
    "          \"val_acc=\", \"{:.5f}\".format(acc), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "    if epoch > FLAGS.early_stopping and cost_val[-1] > np.mean(cost_val[-(FLAGS.early_stopping+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set results: cost= 1.61192 accuracy= 0.27121 time= 6.48976\n",
      "[39.417572, 37.68326, 36.662716, 35.950226, 35.040947, 34.0105, 32.79931, 31.685692, 30.612103, 29.522766, 28.421473, 27.267614, 26.04314, 24.885725, 23.816912, 22.911482, 23.14679, 23.502064, 23.898617, 24.375204, 24.817476, 25.239853, 25.526617, 25.858856, 26.139387, 26.424393, 26.627184, 26.812918, 27.091627, 27.36971, 27.593872, 27.979736, 28.283022, 28.618864, 29.029453, 29.448526, 29.876125, 30.279856, 30.6507, 30.958248, 31.245161, 31.501953, 31.7274, 31.950003, 32.24564, 32.449863, 32.61364, 32.748634, 32.787884, 32.878876, 32.916332, 32.883392, 32.85091, 32.859634, 32.95164, 32.96809, 32.98352, 33.06282, 33.126617, 33.15312, 33.240543, 33.33949, 33.372524, 33.442852, 33.45361, 33.35721, 33.25648, 33.16203, 33.048542, 32.84707, 32.676517, 32.422215, 32.205143, 31.94729, 31.657776, 31.421373, 31.261932, 31.153067, 31.088106, 31.04863, 30.961594, 30.857067, 30.753826, 30.67305, 30.616137, 30.582897, 30.563549, 30.482517, 30.354006, 30.272455, 30.164352, 30.032501, 29.89946, 29.74567, 29.55219, 29.323086, 29.14723, 28.974674, 28.888145, 28.81657, 28.853277, 28.865486, 28.85413, 28.762285, 28.7233, 28.642227, 28.56274, 28.497364, 28.418404, 28.34021, 28.178783, 27.993849, 27.78705, 27.524702, 27.26147, 27.058855, 26.868038, 26.699339, 26.568241, 26.477306, 26.41264, 26.293064, 26.155785, 25.890955, 25.6779, 25.465466, 25.31334, 25.163975, 25.022125, 24.897432, 24.803703, 24.679852, 24.544548, 24.395327, 24.240305, 24.067081, 23.978884, 23.862715, 23.759495, 23.707415, 23.665108, 23.621708, 23.587519, 23.583492, 23.56407, 23.505878, 23.42124, 23.36078, 23.273909, 23.113668, 22.951925, 22.794563, 22.643993, 22.5088, 22.375704, 22.26644, 22.190813, 22.120852, 22.056742, 21.986856, 21.90744, 21.803566, 21.734072, 21.67608, 21.63949, 21.592718, 21.55916, 21.515684, 21.519028, 21.510098, 21.521935, 21.51331, 21.534693, 21.506523, 21.454819, 21.405096, 21.370785, 21.362076, 21.332178, 21.311293, 21.305586, 21.26537, 21.238676, 21.248037, 21.239267, 21.231853, 21.215292, 21.19933, 21.211935, 21.200384, 21.185099, 21.165016, 21.126343, 21.067207, 21.000822, 20.943232, 20.885519, 20.8186, 20.753338, 20.694561, 20.620014, 20.531158, 20.40803, 20.312042, 20.215849, 20.131462, 20.063358, 20.012835, 19.969799, 19.900259, 19.831833, 19.773691, 19.704556, 19.631779, 19.541033, 19.444553, 19.358116, 19.25509, 19.171297, 19.095364, 19.00856, 18.931702, 18.84569, 18.740017, 18.635176, 18.5223, 18.421595, 18.338074, 18.254108, 18.164791, 18.10431, 18.026503, 17.953934, 17.883913, 17.815983, 17.761318, 17.709982, 17.663399, 17.604343, 17.550674, 17.507397, 17.482822, 17.439465, 17.412497, 17.381975, 17.375906, 17.373625, 17.354536, 17.330658, 17.302326, 17.28163, 17.271372, 17.26196, 17.250711, 17.22401, 17.202322, 17.141165, 17.053547, 16.956696, 16.855724, 16.75721, 16.657145, 16.56132, 16.470896, 16.368002, 16.259024, 16.1519, 16.056025, 15.952693, 15.8801985, 15.811672, 15.75001, 15.692529, 15.624673, 15.560894, 15.487743, 15.428719, 15.384416, 15.35308, 15.316533, 15.286866, 15.270329, 15.234061, 15.19657, 15.166243, 15.126927, 15.078023, 15.02507, 14.962917, 14.904273, 14.847864, 14.799075, 14.7539625, 14.690543, 14.622457, 14.563796, 14.506548, 14.445518, 14.388055, 14.317328, 14.247244, 14.178952, 14.124626, 14.077763, 14.039367, 13.996637, 13.963616, 13.933286, 13.908656, 13.881895, 13.855445, 13.834527, 13.801941, 13.771716, 13.739967, 13.717426, 13.6852045, 13.65164, 13.614122, 13.570125, 13.523297, 13.490516, 13.4616, 13.430237, 13.392673, 13.370539, 13.345541, 13.32617, 13.306785, 13.27764, 13.251717, 13.226129, 13.193237, 13.163488, 13.119397, 13.078869, 13.043688, 13.020719, 12.9961815, 12.978743, 12.964351, 12.952267, 12.931184, 12.906711, 12.883161, 12.859063, 12.832977, 12.803479, 12.776082, 12.754237, 12.736577, 12.718399, 12.695682, 12.669103, 12.64119, 12.608586, 12.574644, 12.534717, 12.497195, 12.467277, 12.442218, 12.420238, 12.402106, 12.388087, 12.365966, 12.349249, 12.334696, 12.317066, 12.3000345, 12.275267, 12.2475815, 12.214209, 12.183229, 12.153045, 12.124403, 12.094091, 12.06138, 12.0273695, 11.98948, 11.959962, 11.928063, 11.897041, 11.869489, 11.841488, 11.807763, 11.770553, 11.734192, 11.7065115, 11.67863, 11.64963, 11.624235, 11.604489, 11.581317, 11.56491, 11.548538, 11.53948, 11.533501, 11.525613, 11.517448, 11.496769, 11.472912, 11.4437065, 11.413768, 11.382723, 11.359164, 11.327766, 11.298508, 11.265941, 11.233879, 11.202539, 11.175685, 11.145147, 11.115497, 11.093744, 11.070187, 11.051084, 11.031593, 11.018122, 11.006546, 10.990371, 10.973913, 10.956585, 10.93844, 10.923889, 10.91173, 10.902153, 10.887259, 10.869426, 10.856134, 10.844225, 10.8330765, 10.820047, 10.806406, 10.7948265, 10.773204, 10.753875, 10.735107, 10.725756, 10.717392, 10.71317, 10.703347, 10.690967, 10.67989, 10.671123, 10.66769, 10.662747, 10.65944, 10.655503, 10.651823, 10.651487, 10.648339, 10.645405, 10.643148, 10.641318, 10.639991, 10.626141, 10.615315, 10.608099, 10.606534, 10.606108, 10.604544, 10.600578, 10.607425, 10.606902, 10.600491, 10.594047, 10.5897875, 10.583924, 10.585876, 10.584563, 10.579967, 10.573077, 10.566003, 10.559826, 10.549701, 10.531174, 10.510753, 10.481794, 10.453655, 10.425776, 10.398263, 10.372279, 10.347111, 10.323376, 10.305482, 10.289282, 10.273646, 10.254343, 10.237934, 10.216995, 10.19701, 10.169246, 10.148415, 10.135423, 10.127081, 10.118999, 10.112338, 10.104279, 10.098844, 10.094424, 10.089631, 10.08426, 10.074946, 10.063832, 10.050875, 10.03538, 10.019922, 10.005308, 9.992988, 9.983729, 9.975327, 9.963803, 9.955204, 9.945969, 9.942334, 9.936383, 9.932801, 9.92277, 9.918189, 9.913518, 9.908363, 9.901791, 9.89376, 9.88604, 9.879409, 9.870816, 9.862915, 9.861389, 9.858449, 9.852222, 9.851957, 9.849788, 9.844158, 9.837003, 9.829207, 9.82241, 9.813804, 9.8007345, 9.792123, 9.785175, 9.775914, 9.771568, 9.765019, 9.7589245, 9.755472, 9.752553, 9.7501135, 9.749554, 9.753411, 9.757653, 9.760031, 9.760338, 9.754305, 9.752246, 9.749989, 9.742112, 9.736432, 9.73035, 9.718417, 9.705554, 9.695126, 9.685869, 9.672768, 9.662163, 9.645429, 9.629801, 9.616005, 9.598748, 9.586354, 9.573168, 9.559452, 9.546951, 9.535105, 9.523998, 9.5084305, 9.494049, 9.480888, 9.468289, 9.457125, 9.44763, 9.435136, 9.422319, 9.413264, 9.405222, 9.399969, 9.397623, 9.401088, 9.406423, 9.412339, 9.413399, 9.410703, 9.408969, 9.403836, 9.401006, 9.396119, 9.392272, 9.38678, 9.379749, 9.377226, 9.37749, 9.379124, 9.383648, 9.387163, 9.389396, 9.392253, 9.390905, 9.389496, 9.389017, 9.387938, 9.386796, 9.385622, 9.385392, 9.379884, 9.376493, 9.373369, 9.367088, 9.36394, 9.352434, 9.340164, 9.328136, 9.318291, 9.310491, 9.303294, 9.296503, 9.291675, 9.288433, 9.284099, 9.282135, 9.279377, 9.277779, 9.279425, 9.279595, 9.277583, 9.276268, 9.273137, 9.268265, 9.264188, 9.266605, 9.268582, 9.267928, 9.265951, 9.262717, 9.259636, 9.254372, 9.246677, 9.236786, 9.224412, 9.213505, 9.20301, 9.192123, 9.183174, 9.174688, 9.168476, 9.162437, 9.154586, 9.149225, 9.140864, 9.135862, 9.131997, 9.123889, 9.117205, 9.115212, 9.10722, 9.095748, 9.085688, 9.073956, 9.062079, 9.053425, 9.046844, 9.041009, 9.034462, 9.030446, 9.026341, 9.023576, 9.018221, 9.016023, 9.013906, 9.014775, 9.019579, 9.024237, 9.027786, 9.028969, 9.033035, 9.033731, 9.033312, 9.028801, 9.026957, 9.023696, 9.019493, 9.017926, 9.015406, 9.013414, 9.013823, 9.013957, 9.010734, 9.00348, 8.997937, 8.994128, 8.98756, 8.97692, 8.968455, 8.960881, 8.952148, 8.941501, 8.93038, 8.920678, 8.911553, 8.904155, 8.8975315, 8.892023, 8.884639, 8.875805, 8.867071, 8.859283, 8.85151, 8.844256, 8.835381, 8.823847, 8.814601, 8.808018, 8.801583, 8.796679, 8.793561, 8.789949, 8.787131, 8.785293, 8.783597, 8.781982, 8.780759, 8.7771225, 8.773097, 8.770436, 8.7665, 8.762725, 8.76144, 8.763309, 8.766448, 8.766163, 8.765614, 8.762589, 8.757454, 8.75302, 8.746611, 8.737632, 8.729738, 8.721491, 8.716739, 8.711842, 8.707939, 8.69866, 8.685192, 8.678994, 8.673013, 8.666459, 8.659919, 8.653391, 8.649045, 8.645482, 8.642243, 8.637278, 8.632061, 8.626988, 8.622173, 8.618075, 8.60913, 8.599832, 8.591189, 8.582604, 8.572112, 8.559403, 8.549565, 8.545402, 8.544419, 8.545458, 8.545467, 8.546754, 8.548514, 8.551336, 8.556208, 8.560292, 8.563746, 8.569747, 8.578432, 8.586871, 8.5897665, 8.591504, 8.588024, 8.582108, 8.5701475, 8.559227, 8.550489, 8.5455475, 8.536397, 8.530713, 8.528401, 8.524762, 8.520801, 8.515114, 8.510545, 8.508399, 8.503222, 8.498897, 8.497057, 8.494631, 8.495882, 8.4970045, 8.496076, 8.492089, 8.486644, 8.476056, 8.462605, 8.450269, 8.442498, 8.436517, 8.435278, 8.43604, 8.438077, 8.441489, 8.445411, 8.444248, 8.442916, 8.441878, 8.43634, 8.431956, 8.425227, 8.419292, 8.414645, 8.411016, 8.408254, 8.406579, 8.405602, 8.403516, 8.400999, 8.398015, 8.395243, 8.3932295, 8.391886, 8.390558, 8.388379, 8.3857765, 8.383368, 8.382302, 8.381433, 8.380593, 8.378572, 8.37653, 8.375473, 8.3746805, 8.374515, 8.3729105, 8.371697, 8.369482, 8.368672, 8.36877, 8.36837, 8.368662, 8.368086, 8.366246, 8.363093, 8.35827, 8.354196, 8.349623, 8.345177, 8.34272, 8.340625, 8.340368, 8.33882, 8.339338, 8.341214, 8.344954, 8.347152, 8.350387, 8.352211, 8.354692, 8.357281, 8.355765, 8.352225, 8.347723, 8.342279, 8.333776, 8.325427, 8.317336, 8.309435, 8.302111, 8.296363, 8.292352, 8.28944, 8.289129, 8.290398, 8.291015, 8.290469, 8.288586, 8.2856045, 8.28188, 8.27924, 8.275809, 8.272625, 8.268798, 8.266597, 8.263477, 8.260681, 8.257609, 8.254928, 8.253371, 8.252028, 8.251193, 8.249424, 8.248318, 8.247126, 8.246769, 8.246191, 8.245629, 8.245347, 8.244997, 8.242567, 8.241389, 8.242216, 8.243603, 8.244336, 8.245411, 8.246497, 8.246698, 8.244116, 8.238405, 8.231777, 8.228141, 8.224433, 8.21965, 8.215755, 8.212301, 8.208702, 8.205035, 8.203298, 8.2035265, 8.204989, 8.207787, 8.211115, 8.214319, 8.216674, 8.215735, 8.213718, 8.210911, 8.2084255, 8.204999, 8.202178, 8.199911, 8.19868, 8.19816, 8.197224, 8.196938, 8.196862, 8.195776, 8.194606, 8.191714, 8.188211, 8.184307, 8.180427, 8.178019, 8.176818, 8.175094, 8.17386, 8.173624, 8.172694, 8.172038, 8.171554, 8.169192, 8.167599, 8.166851, 8.166151, 8.165114, 8.165121, 8.1648245, 8.16179, 8.158202, 8.155543, 8.154458, 8.15392, 8.15547, 8.157049, 8.15914, 8.1613, 8.163639, 8.165282, 8.166315, 8.164071, 8.16421, 8.163803, 8.163444, 8.164291, 8.164667, 8.164941, 8.1668005, 8.170385, 8.172814, 8.176091, 8.180942, 8.185884, 8.190415, 8.195367, 8.198434, 8.200571, 8.200756, 8.19694, 8.1929455, 8.18969, 8.186197, 8.18368, 8.182579, 8.179989, 8.177787, 8.175865, 8.1734085, 8.172414, 8.17343, 8.175325, 8.176896, 8.179173, 8.180329, 8.179165, 8.17843, 8.1772175, 8.17552, 8.174181, 8.171906, 8.169067, 8.163988, 8.159159, 8.154727, 8.149862, 8.147194, 8.144375, 8.143056, 8.141914, 8.140678, 8.140048, 8.140191, 8.140693, 8.141324, 8.142359, 8.144749, 8.148514, 8.153386, 8.156838, 8.159688, 8.1620245, 8.16732, 8.173058, 8.176461, 8.176982, 8.176031, 8.173147, 8.169219, 8.1644745, 8.159931, 8.1546545, 8.149975, 8.146316, 8.144097, 8.141641, 8.138195, 8.134942, 8.132255, 8.129739, 8.1284275, 8.128278, 8.130432, 8.131593, 8.131541, 8.131924, 8.132371, 8.13381, 8.136304, 8.137136, 8.138031, 8.138002, 8.13823, 8.13883, 8.136975, 8.135606, 8.134271, 8.132882, 8.13218, 8.131554, 8.132406, 8.133784, 8.136709, 8.138015, 8.137172, 8.136679, 8.135982, 8.135526, 8.13446, 8.131296, 8.128135, 8.123843, 8.12012, 8.117689, 8.116069, 8.11388, 8.11256, 8.111661, 8.111751, 8.113064, 8.113676, 8.113906, 8.113895, 8.112898, 8.111573, 8.109815, 8.108242, 8.10706, 8.104942, 8.103184, 8.102582, 8.103105, 8.104378, 8.106204, 8.108062, 8.10914, 8.109921, 8.109442, 8.107673, 8.10757, 8.108667, 8.108963, 8.109178, 8.109544, 8.108798, 8.107366, 8.1053, 8.102933, 8.100046, 8.097937, 8.096509, 8.09514, 8.094257, 8.093813, 8.094278, 8.094077, 8.094233, 8.094849, 8.095644, 8.096058, 8.09674, 8.097412, 8.099727, 8.100868, 8.10179, 8.10172, 8.102478, 8.104099, 8.105521, 8.106447, 8.106531, 8.10682, 8.106289, 8.105956, 8.105233, 8.105059, 8.103998, 8.103884, 8.106927, 8.109243, 8.11134, 8.11322, 8.115881, 8.120024, 8.121724, 8.121377, 8.12103, 8.121505, 8.122562, 8.121428, 8.117954, 8.11429, 8.110654, 8.106053, 8.102999, 8.100861, 8.100611, 8.10005, 8.098815, 8.097293, 8.096754, 8.09571, 8.095474, 8.0962925, 8.09741, 8.098566, 8.098055, 8.097754, 8.097473, 8.097394, 8.0966215, 8.095594, 8.094684, 8.09359, 8.092852, 8.092174, 8.091414, 8.091409, 8.090881, 8.090594, 8.090377, 8.090576, 8.091345, 8.093039, 8.0942955, 8.095577, 8.096215, 8.097074, 8.097492, 8.097713, 8.098205, 8.09915, 8.099531, 8.100538, 8.101341, 8.102146, 8.102528, 8.103614, 8.10392, 8.103768, 8.102947, 8.10149, 8.099537, 8.098376, 8.097384, 8.097678, 8.09902, 8.098795, 8.098247, 8.098206, 8.097926, 8.097369, 8.09681, 8.096228, 8.09541, 8.095503, 8.095579, 8.096002, 8.095822, 8.095588, 8.095642, 8.096689, 8.097558, 8.098825, 8.099382, 8.1001, 8.101096, 8.10272, 8.105708, 8.1079035, 8.107553, 8.105353, 8.100729, 8.097426, 8.095029, 8.093579, 8.091609, 8.089706, 8.088248, 8.087083, 8.085757, 8.085638, 8.085888, 8.086307, 8.086928, 8.088793, 8.091384, 8.095035, 8.0988455, 8.103363, 8.104768, 8.105501, 8.103443, 8.101969, 8.100795, 8.100706, 8.100728, 8.100205, 8.098737, 8.096964, 8.09556, 8.093618, 8.091822, 8.090307, 8.088181, 8.085023, 8.083037, 8.0823345, 8.082574, 8.083586, 8.085047, 8.086321, 8.086867, 8.08752, 8.0883255, 8.089245, 8.089914, 8.0907545, 8.092345, 8.093197, 8.094193, 8.094072, 8.092076, 8.090664, 8.088983, 8.087331, 8.085984, 8.086372, 8.08751, 8.087613, 8.088011, 8.088699, 8.089961, 8.089908, 8.089898, 8.089822, 8.09025, 8.090536, 8.090745, 8.091346, 8.092213, 8.092189, 8.091655, 8.091203, 8.090779, 8.090051, 8.089699, 8.089504, 8.088893, 8.088374, 8.087697, 8.086663, 8.085645, 8.084336, 8.083488, 8.083866, 8.083893, 8.0845175, 8.085946, 8.08592, 8.08634, 8.087846, 8.088615, 8.089857, 8.089635, 8.0886345, 8.087969, 8.0870905, 8.086644, 8.08693, 8.087643, 8.089751, 8.092484, 8.09443, 8.095991, 8.097779, 8.097506, 8.096529, 8.095423, 8.092646, 8.090822, 8.090413, 8.0909815, 8.090265, 8.090578, 8.0908985, 8.091227, 8.092297, 8.092543, 8.092594, 8.091574, 8.090516, 8.090214, 8.090294, 8.091467, 8.093393, 8.095202, 8.095161, 8.094642, 8.094143, 8.093362, 8.092502, 8.090305, 8.087616, 8.085962, 8.085594, 8.086102, 8.086392, 8.086704, 8.086952, 8.086864, 8.087159, 8.088586, 8.08933, 8.089428, 8.089602, 8.089748, 8.09133, 8.09218, 8.093729, 8.09511, 8.095604, 8.095638, 8.0955515, 8.09572, 8.095388, 8.095471, 8.099493, 8.103017, 8.1069565, 8.111063, 8.112877, 8.1136675, 8.114299, 8.114071, 8.112268, 8.110673, 8.1097975, 8.107405, 8.104303, 8.101585, 8.098662, 8.094158, 8.091425, 8.087937, 8.085584, 8.084855, 8.085601, 8.087113, 8.088916, 8.090656, 8.091742, 8.093019, 8.094814, 8.096673, 8.098621, 8.101297, 8.102447, 8.102532, 8.10218, 8.100231, 8.0973835, 8.094764, 8.092539, 8.091094, 8.090409, 8.090088, 8.089929, 8.089466, 8.089036, 8.088712, 8.088804, 8.087158, 8.085925, 8.085376, 8.085361, 8.085613, 8.086336, 8.087019, 8.087485, 8.087044, 8.086076, 8.084456, 8.082154, 8.081186, 8.081114, 8.081596, 8.081935, 8.081804, 8.081357, 8.080867, 8.080536, 8.081141, 8.082514, 8.083158, 8.083387, 8.083042, 8.082425, 8.080952, 8.0799, 8.079699, 8.080183, 8.081165, 8.082584, 8.084319, 8.085967, 8.087968, 8.090628, 8.093173, 8.094612, 8.094417, 8.092878, 8.090412, 8.08849, 8.08825, 8.088934, 8.089694, 8.090338, 8.0895605, 8.089448, 8.088975, 8.089074, 8.089172, 8.089735, 8.09009, 8.090325, 8.0899935, 8.089668, 8.087973, 8.086808, 8.086025, 8.084783, 8.083657, 8.082996, 8.082846, 8.082745, 8.082968, 8.082865, 8.08301, 8.082934, 8.083288, 8.083609, 8.084064, 8.084723, 8.086175, 8.088886, 8.092509, 8.095765, 8.098896, 8.101329, 8.102019, 8.101581, 8.100401, 8.099837, 8.099122, 8.098615, 8.098836, 8.09966, 8.099253, 8.098894, 8.097584, 8.095536, 8.093153, 8.090796, 8.089198, 8.087097, 8.085745, 8.0852, 8.084802, 8.084221, 8.083953, 8.083538, 8.083434, 8.083564, 8.083987, 8.085524, 8.086955, 8.086847, 8.087123, 8.087402, 8.087847, 8.087951, 8.087753, 8.087826, 8.087976, 8.088311, 8.089122, 8.090625, 8.091002, 8.092124, 8.0938, 8.0943575, 8.093319, 8.091966, 8.090808, 8.090029, 8.088891, 8.088261, 8.087923, 8.087257, 8.087049, 8.08703, 8.086771, 8.08605, 8.086409, 8.088273, 8.089869, 8.091355, 8.092187, 8.0925, 8.091958, 8.091038, 8.089707, 8.08838, 8.086792, 8.085434, 8.083948, 8.082487, 8.080189, 8.077905, 8.076234, 8.074801, 8.074215, 8.074245, 8.07508, 8.076019, 8.076855, 8.077035, 8.077642, 8.0782995, 8.078768, 8.07882, 8.078984, 8.079368, 8.079991, 8.081062, 8.083113, 8.08474, 8.086549, 8.088158, 8.0896, 8.090516, 8.090477, 8.089874, 8.089483, 8.089485, 8.089434, 8.0891075, 8.088402, 8.0876465, 8.087126, 8.086376, 8.085749, 8.085148, 8.083994, 8.082751, 8.082045, 8.081634, 8.081703, 8.082182, 8.082943, 8.084218, 8.084756, 8.085606, 8.08627, 8.086262, 8.086142, 8.086367, 8.087194, 8.087863, 8.087621, 8.086844, 8.08669, 8.086486, 8.086266, 8.0867195, 8.087006, 8.086948, 8.086237, 8.085821, 8.084796, 8.083793, 8.083114, 8.083152, 8.082804, 8.083545, 8.083773, 8.083921, 8.083063, 8.082715, 8.082431, 8.081722, 8.081391, 8.08041, 8.080036, 8.079845, 8.0793295, 8.079222, 8.078781, 8.078619, 8.078773, 8.079094, 8.079371, 8.080533, 8.08142, 8.082448, 8.083749, 8.085207, 8.086164, 8.086977, 8.087522, 8.088409, 8.088937, 8.089388, 8.089774, 8.089446, 8.088385, 8.0872135, 8.086377, 8.085883, 8.085508, 8.084619, 8.084804, 8.085745, 8.086802, 8.0879545, 8.08762, 8.086347, 8.0849085, 8.083517, 8.082432, 8.082001, 8.081731, 8.0814905, 8.080954, 8.081172, 8.081718, 8.083091, 8.084005, 8.085543, 8.085579, 8.084863, 8.085283, 8.085848, 8.086468, 8.087229, 8.088196, 8.088797, 8.08832, 8.0882225, 8.0882435, 8.08831, 8.088212, 8.088377, 8.087966, 8.087282, 8.085907, 8.084637, 8.083636, 8.082981, 8.082244, 8.081673, 8.081638, 8.081646, 8.081118, 8.080712, 8.080595, 8.080691, 8.081502, 8.082236, 8.083035, 8.08381, 8.083545, 8.082282, 8.081258, 8.0804, 8.080165, 8.080002, 8.079967, 8.080091, 8.0798025, 8.080052, 8.080085, 8.080288, 8.080679, 8.081095, 8.081533, 8.081971, 8.082178, 8.08276, 8.083178, 8.083305, 8.083091, 8.08274, 8.081656, 8.080109, 8.079481, 8.07887, 8.078682, 8.078715, 8.079266, 8.079886, 8.080813, 8.08142, 8.081752, 8.081715, 8.081259, 8.081182, 8.081227, 8.080783, 8.080774, 8.080977, 8.080934, 8.081919, 8.0837555, 8.085771, 8.087394, 8.088641, 8.089841, 8.09063, 8.091141, 8.091754, 8.092856, 8.0939665, 8.094553, 8.094466, 8.094311, 8.094439, 8.094825, 8.095092, 8.095918, 8.097004, 8.098048, 8.0985775, 8.096931, 8.094242, 8.092048, 8.090232, 8.088816, 8.088034, 8.087303, 8.086938, 8.087352, 8.086899, 8.086451, 8.086546, 8.086768, 8.086639, 8.0864935, 8.085763, 8.085575, 8.085851, 8.086433, 8.087114, 8.087591, 8.087674, 8.086671, 8.085556, 8.084297, 8.083715, 8.083062, 8.082371, 8.081677, 8.081133, 8.080906, 8.080484, 8.07994, 8.079457, 8.079514, 8.079675, 8.077798, 8.076522, 8.075574, 8.074852, 8.074914, 8.075479, 8.075948, 8.076288, 8.076488, 8.076906, 8.077667, 8.07793, 8.078752, 8.07886, 8.079967, 8.08101, 8.081848, 8.082648, 8.08329, 8.08381, 8.084202, 8.08458, 8.085399, 8.086181, 8.087203, 8.088187, 8.088934, 8.088964, 8.08872, 8.087928, 8.087346, 8.08676, 8.086068, 8.085623, 8.085729, 8.0859785, 8.086931, 8.087406, 8.087813, 8.088354, 8.089071, 8.089826, 8.090243, 8.09039, 8.090729, 8.09053, 8.089174, 8.087789, 8.086285, 8.085231, 8.0834675, 8.082135, 8.080435, 8.079295, 8.078683, 8.0778885, 8.077064, 8.076874, 8.076452, 8.076301, 8.076493, 8.077219, 8.078197, 8.079538, 8.0805235, 8.081528, 8.082189, 8.082387, 8.082723, 8.0825815, 8.08203, 8.081591, 8.081096, 8.080335, 8.07907, 8.078059, 8.077298, 8.076515, 8.076341, 8.076305, 8.077003, 8.078016, 8.079462, 8.080887, 8.082481, 8.083756, 8.085173, 8.086737, 8.088827, 8.089601, 8.089727, 8.089892, 8.090263, 8.089766, 8.0891285, 8.08874, 8.088052, 8.087656, 8.087507, 8.087101, 8.087041, 8.087173, 8.087456, 8.087711, 8.087474, 8.086635, 8.085551, 8.08439, 8.0833645, 8.082803, 8.083486, 8.0840025, 8.084472, 8.084622, 8.084636, 8.084628, 8.084816, 8.08529, 8.085801, 8.08636, 8.086331, 8.085663, 8.084742, 8.083227, 8.081928, 8.0814705, 8.081263, 8.08092, 8.080683, 8.079755, 8.07752, 8.07543, 8.0744295, 8.074117, 8.074406, 8.075561, 8.077019, 8.077888, 8.078458, 8.078492, 8.077976, 8.077171, 8.076907, 8.07689, 8.077086, 8.077142, 8.077009]\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_cost, test_acc, test_duration = evaluate(features, support, test_labels_mat, test_mask_mat[:,1], placeholders, sess, model)\n",
    "print(\"Test set results:\", \"cost=\", \"{:.5f}\".format(test_cost),\n",
    "      \"accuracy=\", \"{:.5f}\".format(test_acc), \"time=\", \"{:.5f}\".format(test_duration))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
