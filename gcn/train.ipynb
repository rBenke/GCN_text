{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from utils import *\n",
    "from models import GCN, MLP\n",
    "\n",
    "# Set random seed\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths to available grahs metadata\n",
    "adj_mat, features_mat, train_labels_mat, test_labels_mat, val_labels_mat, train_mask_mat, test_mask_mat, val_mask_mat = load_data(\"txt_graph2216_21012020\", 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16542, 16542)\n",
      "(16542, 100)\n",
      "(16542, 5)\n",
      "(16542, 5)\n",
      "(16542, 5)\n",
      "(16542, 5)\n",
      "(16542, 5)\n",
      "(16542, 5)\n"
     ]
    }
   ],
   "source": [
    "print(adj_mat.shape)\n",
    "print(features_mat.shape)\n",
    "print(train_labels_mat.shape)\n",
    "print(test_labels_mat.shape)\n",
    "print(val_labels_mat.shape)\n",
    "print(train_mask_mat.shape)\n",
    "print(test_mask_mat.shape)\n",
    "print(val_mask_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete all flags before declaration new one\n",
    "del_all_flags(tf.flags.FLAGS)\n",
    "\n",
    "# Settings\n",
    "flags = tf.app.flags\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('mode', '', 'kernel') # for line by line mode\n",
    "tf.app.flags.DEFINE_string('port', '', 'kernel') # for line by line mode\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel') # for jupyter notebook\n",
    "\n",
    "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 200, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 16, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_float('dropout', 0.5, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('weight_decay', 5e-4, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_integer('early_stopping', 50, 'Tolerance for early stopping (# of epochs).')\n",
    "\n",
    "# Some preprocessing\n",
    "features = preprocess_features(features_mat)\n",
    "support = [preprocess_adj(adj_mat)]\n",
    "num_supports = 1\n",
    "model_func = GCN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "placeholders = {\n",
    "    'support': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n",
    "    'labels': tf.placeholder(tf.float32, shape=(None, train_labels_mat.shape[1])),\n",
    "    'labels_mask': tf.placeholder(tf.int32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    'num_features_nonzero': tf.placeholder(tf.int32)  # helper variable for sparse dropout\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = model_func(placeholders, input_dim=features[2][1], logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "# Init variables\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<models.GCN at 0x7f3c004a9e48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.63588 train_acc= 0.27825 val_loss= 45.02081 val_acc= 0.16773 time= 0.32626\n",
      "Epoch: 0002 train_loss= 1.63750 train_acc= 0.27575 val_loss= 44.60149 val_acc= 0.16942 time= 0.30999\n",
      "Epoch: 0003 train_loss= 1.67574 train_acc= 0.27047 val_loss= 44.08991 val_acc= 0.17281 time= 0.31172\n",
      "Epoch: 0004 train_loss= 1.63165 train_acc= 0.28333 val_loss= 43.70113 val_acc= 0.17535 time= 0.29996\n",
      "Epoch: 0005 train_loss= 1.63680 train_acc= 0.26918 val_loss= 43.30085 val_acc= 0.17831 time= 0.31037\n",
      "Epoch: 0006 train_loss= 1.65396 train_acc= 0.28121 val_loss= 42.99154 val_acc= 0.17704 time= 0.30349\n",
      "Epoch: 0007 train_loss= 1.66311 train_acc= 0.27232 val_loss= 42.77729 val_acc= 0.17577 time= 0.30056\n",
      "Epoch: 0008 train_loss= 1.63266 train_acc= 0.27001 val_loss= 42.83186 val_acc= 0.17493 time= 0.30015\n",
      "Epoch: 0009 train_loss= 1.62589 train_acc= 0.28639 val_loss= 42.90338 val_acc= 0.17027 time= 0.30440\n",
      "Epoch: 0010 train_loss= 1.64319 train_acc= 0.26372 val_loss= 43.20482 val_acc= 0.16222 time= 0.29994\n",
      "Epoch: 0011 train_loss= 1.65183 train_acc= 0.26825 val_loss= 43.41860 val_acc= 0.15798 time= 0.30200\n",
      "Epoch: 0012 train_loss= 1.62734 train_acc= 0.28916 val_loss= 43.80146 val_acc= 0.15205 time= 0.30947\n",
      "Epoch: 0013 train_loss= 1.62719 train_acc= 0.28019 val_loss= 44.26310 val_acc= 0.14570 time= 0.30033\n",
      "Epoch: 0014 train_loss= 1.63026 train_acc= 0.28000 val_loss= 44.84068 val_acc= 0.13511 time= 0.30578\n",
      "Epoch: 0015 train_loss= 1.62940 train_acc= 0.27880 val_loss= 45.37597 val_acc= 0.12495 time= 0.30416\n",
      "Epoch: 0016 train_loss= 1.87713 train_acc= 0.27390 val_loss= 45.24672 val_acc= 0.12452 time= 0.30329\n",
      "Epoch: 0017 train_loss= 1.60347 train_acc= 0.28454 val_loss= 45.15874 val_acc= 0.12495 time= 0.29989\n",
      "Epoch: 0018 train_loss= 1.60603 train_acc= 0.27714 val_loss= 44.71909 val_acc= 0.12706 time= 0.30550\n",
      "Epoch: 0019 train_loss= 1.65226 train_acc= 0.26446 val_loss= 44.28825 val_acc= 0.13045 time= 0.30342\n",
      "Epoch: 0020 train_loss= 1.63420 train_acc= 0.27788 val_loss= 43.47828 val_acc= 0.13469 time= 0.30924\n",
      "Epoch: 0021 train_loss= 1.61871 train_acc= 0.27214 val_loss= 42.66788 val_acc= 0.13808 time= 0.30704\n",
      "Epoch: 0022 train_loss= 1.61616 train_acc= 0.29018 val_loss= 41.60616 val_acc= 0.14274 time= 0.30671\n",
      "Epoch: 0023 train_loss= 1.62507 train_acc= 0.27362 val_loss= 40.53704 val_acc= 0.15205 time= 0.30344\n",
      "Epoch: 0024 train_loss= 1.63784 train_acc= 0.27973 val_loss= 39.55090 val_acc= 0.15460 time= 0.31667\n",
      "Epoch: 0025 train_loss= 1.59639 train_acc= 0.27195 val_loss= 38.82191 val_acc= 0.15714 time= 0.32345\n",
      "Epoch: 0026 train_loss= 1.60322 train_acc= 0.27862 val_loss= 38.34864 val_acc= 0.15756 time= 0.32714\n",
      "Epoch: 0027 train_loss= 1.61448 train_acc= 0.28509 val_loss= 37.74233 val_acc= 0.16010 time= 0.37779\n",
      "Epoch: 0028 train_loss= 1.92534 train_acc= 0.27732 val_loss= 37.04532 val_acc= 0.16900 time= 0.31500\n",
      "Epoch: 0029 train_loss= 1.60778 train_acc= 0.27565 val_loss= 36.58178 val_acc= 0.17450 time= 0.30748\n",
      "Epoch: 0030 train_loss= 1.61301 train_acc= 0.28630 val_loss= 36.14028 val_acc= 0.17535 time= 0.30886\n",
      "Epoch: 0031 train_loss= 1.60854 train_acc= 0.27723 val_loss= 35.90302 val_acc= 0.17366 time= 0.34426\n",
      "Epoch: 0032 train_loss= 1.63139 train_acc= 0.28898 val_loss= 35.80008 val_acc= 0.16984 time= 0.33111\n",
      "Epoch: 0033 train_loss= 1.60641 train_acc= 0.27334 val_loss= 35.88935 val_acc= 0.16095 time= 0.34442\n",
      "Epoch: 0034 train_loss= 1.61660 train_acc= 0.28250 val_loss= 35.94456 val_acc= 0.15671 time= 0.32189\n",
      "Epoch: 0035 train_loss= 1.60946 train_acc= 0.27695 val_loss= 36.15401 val_acc= 0.15417 time= 0.30059\n",
      "Epoch: 0036 train_loss= 1.61108 train_acc= 0.27917 val_loss= 36.55295 val_acc= 0.14740 time= 0.30027\n",
      "Epoch: 0037 train_loss= 1.59595 train_acc= 0.28611 val_loss= 36.92815 val_acc= 0.14147 time= 0.30312\n",
      "Epoch: 0038 train_loss= 1.59834 train_acc= 0.27714 val_loss= 37.36011 val_acc= 0.13892 time= 0.31020\n",
      "Epoch: 0039 train_loss= 1.60546 train_acc= 0.28824 val_loss= 37.92908 val_acc= 0.12834 time= 0.33968\n",
      "Epoch: 0040 train_loss= 1.62930 train_acc= 0.27760 val_loss= 38.18743 val_acc= 0.12495 time= 0.39706\n",
      "Epoch: 0041 train_loss= 1.59003 train_acc= 0.29120 val_loss= 38.56137 val_acc= 0.12156 time= 0.32330\n",
      "Epoch: 0042 train_loss= 1.58624 train_acc= 0.29000 val_loss= 38.96089 val_acc= 0.11775 time= 0.39739\n",
      "Epoch: 0043 train_loss= 1.61776 train_acc= 0.26807 val_loss= 39.27414 val_acc= 0.11436 time= 0.38766\n",
      "Epoch: 0044 train_loss= 1.60332 train_acc= 0.28426 val_loss= 39.61977 val_acc= 0.11182 time= 0.43534\n",
      "Epoch: 0045 train_loss= 1.61510 train_acc= 0.28509 val_loss= 39.89009 val_acc= 0.11055 time= 0.38122\n",
      "Epoch: 0046 train_loss= 1.61294 train_acc= 0.28990 val_loss= 39.94711 val_acc= 0.10970 time= 0.32859\n",
      "Epoch: 0047 train_loss= 1.58937 train_acc= 0.28824 val_loss= 40.00316 val_acc= 0.11012 time= 0.34751\n",
      "Epoch: 0048 train_loss= 1.58875 train_acc= 0.28731 val_loss= 40.05307 val_acc= 0.10801 time= 0.37342\n",
      "Epoch: 0049 train_loss= 1.60287 train_acc= 0.27751 val_loss= 40.12048 val_acc= 0.10631 time= 0.33024\n",
      "Epoch: 0050 train_loss= 1.59873 train_acc= 0.28750 val_loss= 40.11219 val_acc= 0.10377 time= 0.36125\n",
      "Epoch: 0051 train_loss= 1.60347 train_acc= 0.29027 val_loss= 39.89362 val_acc= 0.10292 time= 0.34836\n",
      "Epoch: 0052 train_loss= 1.58956 train_acc= 0.28963 val_loss= 39.62475 val_acc= 0.10335 time= 0.34959\n",
      "Epoch: 0053 train_loss= 1.58613 train_acc= 0.28546 val_loss= 39.31535 val_acc= 0.10546 time= 0.33167\n",
      "Epoch: 0054 train_loss= 1.59751 train_acc= 0.29027 val_loss= 38.98914 val_acc= 0.10589 time= 0.34103\n",
      "Epoch: 0055 train_loss= 1.59333 train_acc= 0.28306 val_loss= 38.61765 val_acc= 0.10631 time= 0.30905\n",
      "Epoch: 0056 train_loss= 1.59512 train_acc= 0.28306 val_loss= 38.22958 val_acc= 0.10377 time= 0.34682\n",
      "Epoch: 0057 train_loss= 1.60247 train_acc= 0.28324 val_loss= 37.85570 val_acc= 0.10419 time= 0.37501\n",
      "Epoch: 0058 train_loss= 1.60797 train_acc= 0.28111 val_loss= 37.50597 val_acc= 0.10716 time= 0.30304\n",
      "Epoch: 0059 train_loss= 1.61025 train_acc= 0.28250 val_loss= 37.10078 val_acc= 0.11309 time= 0.30966\n",
      "Epoch: 0060 train_loss= 1.59644 train_acc= 0.28102 val_loss= 36.69021 val_acc= 0.12071 time= 0.35054\n",
      "Epoch: 0061 train_loss= 1.60859 train_acc= 0.28019 val_loss= 36.30310 val_acc= 0.12452 time= 0.39505\n",
      "Epoch: 0062 train_loss= 1.59540 train_acc= 0.27843 val_loss= 35.92956 val_acc= 0.12749 time= 0.40797\n",
      "Epoch: 0063 train_loss= 1.62198 train_acc= 0.28380 val_loss= 35.46867 val_acc= 0.13045 time= 0.42082\n",
      "Epoch: 0064 train_loss= 1.61623 train_acc= 0.28796 val_loss= 35.15395 val_acc= 0.12834 time= 0.33570\n",
      "Epoch: 0065 train_loss= 1.60983 train_acc= 0.28537 val_loss= 34.95905 val_acc= 0.12664 time= 0.30981\n",
      "Epoch: 0066 train_loss= 1.59727 train_acc= 0.27852 val_loss= 35.19487 val_acc= 0.12029 time= 0.30267\n",
      "Epoch: 0067 train_loss= 1.60282 train_acc= 0.28482 val_loss= 35.41778 val_acc= 0.11521 time= 0.30156\n",
      "Epoch: 0068 train_loss= 1.59362 train_acc= 0.29324 val_loss= 35.77245 val_acc= 0.11309 time= 0.29887\n",
      "Epoch: 0069 train_loss= 1.60524 train_acc= 0.28833 val_loss= 36.27625 val_acc= 0.11182 time= 0.30728\n",
      "Epoch: 0070 train_loss= 1.63540 train_acc= 0.28741 val_loss= 36.75185 val_acc= 0.10885 time= 0.31303\n",
      "Epoch: 0071 train_loss= 1.59616 train_acc= 0.28778 val_loss= 37.27549 val_acc= 0.10462 time= 0.32054\n",
      "Epoch: 0072 train_loss= 1.58710 train_acc= 0.27908 val_loss= 38.11919 val_acc= 0.09784 time= 0.31776\n",
      "Early stopping...\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "cost_val = []\n",
    "\n",
    "for epoch in range(FLAGS.epochs):\n",
    "\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(features, support, train_labels_mat, train_mask_mat[:,1], placeholders)\n",
    "    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "\n",
    "    # Training step\n",
    "    outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "\n",
    "    # Validation\n",
    "    cost, acc, duration = evaluate(features, support, val_mask_mat, val_mask_mat[:,1], placeholders, sess, model)\n",
    "    cost_val.append(cost)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "          \"train_acc=\", \"{:.5f}\".format(outs[2]), \"val_loss=\", \"{:.5f}\".format(cost),\n",
    "          \"val_acc=\", \"{:.5f}\".format(acc), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "    if epoch > FLAGS.early_stopping and cost_val[-1] > np.mean(cost_val[-(FLAGS.early_stopping+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set results: cost= 1.63567 accuracy= 0.10729 time= 0.18900\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_cost, test_acc, test_duration = evaluate(features, support, test_labels_mat, test_mask_mat[:,1], placeholders, sess, model)\n",
    "print(\"Test set results:\", \"cost=\", \"{:.5f}\".format(test_cost),\n",
    "      \"accuracy=\", \"{:.5f}\".format(test_acc), \"time=\", \"{:.5f}\".format(test_duration))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "graph"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
