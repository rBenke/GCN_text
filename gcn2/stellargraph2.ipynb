{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "VersionCheck"
    ]
   },
   "outputs": [],
   "source": [
    "# verify that we're using the correct version of StellarGraph for this notebook\n",
    "import stellargraph as sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph.mapper import PaddedGraphGenerator\n",
    "from stellargraph.layer import GCNSupervisedGraphClassification\n",
    "from stellargraph import StellarGraph\n",
    "\n",
    "from stellargraph import datasets\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "max_sample = 9999\n",
    "\n",
    "features_files = [f for f in os.listdir(data_path) if f.startswith(\"txt_feature\")]\n",
    "feature_file = open(data_path + features_files[0],'rb')\n",
    "features = pkl.load(feature_file)\n",
    "feature_file.close()\n",
    "\n",
    "files = [f for f in os.listdir(data_path) if f.startswith(\"txt_graph\")]\n",
    "\n",
    "if max_sample < len(files):\n",
    "    files = np.random.choice(files,max_sample,False) \n",
    "else: \n",
    "    files = np.array(files)\n",
    "\n",
    "graphs = []\n",
    "graph_labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and concatenate all graph data\n",
    "for i in range(files.size):\n",
    "    \n",
    "    file = open(data_path + files[i],'rb')\n",
    " \n",
    "    graph = pkl.load(file)\n",
    "    label = pkl.load(file)\n",
    "    \n",
    "    pd.DataFrame(graph.edges)\n",
    "    features.loc[np.unique(list(graph.nodes)),:]\n",
    "    \n",
    "    graphs.append(StellarGraph(edges =  pd.DataFrame(graph.edges, columns=[\"source\", \"target\"]),\n",
    "                                   node_features = features.loc[np.unique(list(graph.nodes)),:]))\n",
    "    graph_labels.append(label)\n",
    "    \n",
    "    file.close()\n",
    "\n",
    "\n",
    "features_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 247, Edges: 403\n",
      "\n",
      " Node types:\n",
      "  default: [247]\n",
      "    Features: none\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [403]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "print(graphs[0].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StellarGraph: Undirected multigraph\n",
      " Nodes: 209, Edges: 321\n",
      "\n",
      " Node types:\n",
      "  default: [209]\n",
      "    Features: none\n",
      "    Edge types: default-default->default\n",
      "\n",
      " Edge types:\n",
      "    default-default->default: [321]\n",
      "        Weights: all 1 (default)\n",
      "        Features: none\n"
     ]
    }
   ],
   "source": [
    "print(graphs[1].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistics of the sizes of the graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodes</th>\n",
       "      <th>edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2225.0</td>\n",
       "      <td>2225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>208.2</td>\n",
       "      <td>305.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>89.5</td>\n",
       "      <td>173.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>57.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>149.0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>189.0</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>250.0</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1342.0</td>\n",
       "      <td>3072.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nodes   edges\n",
       "count  2225.0  2225.0\n",
       "mean    208.2   305.1\n",
       "std      89.5   173.5\n",
       "min      57.0    52.0\n",
       "25%     149.0   199.0\n",
       "50%     189.0   268.0\n",
       "75%     250.0   374.0\n",
       "max    1342.0  3072.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame(\n",
    "    [(g.number_of_nodes(), g.number_of_edges()) for g in graphs],\n",
    "    columns=[\"nodes\", \"edges\"],\n",
    ")\n",
    "summary.describe().round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are `1` or `-1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3970dddb4168>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'value_counts'"
     ]
    }
   ],
   "source": [
    "graph_labels.value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_labels = pd.get_dummies(graph_labels, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare graph generator\n",
    "\n",
    "To feed data to the `tf.Keras` model that we will create later, we need a data generator. For supervised graph classification, we create an instance of `StellarGraph`'s `PaddedGraphGenerator` class. Note that `graphs` is a list of `StellarGraph` graph objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = PaddedGraphGenerator(graphs=graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Keras graph classification model\n",
    "\n",
    "We are now ready to create a `tf.Keras` graph classification model using `StellarGraph`'s `GraphClassification` class together with standard `tf.Keras` layers, e.g., `Dense`. \n",
    "\n",
    "The input is the graph represented by its adjacency and node features matrices. The first two layers are Graph Convolutional as in [2] with each layer having 64 units and `relu` activations. The next layer is a mean pooling layer where the learned node representation are summarized to create a graph representation. The graph representation is input to two fully connected layers with 32 and 16 units respectively and `relu` activations. The last layer is the output layer with a single unit and `sigmoid` activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](graph_classification_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_classification_model(generator):\n",
    "    gc_model = GCNSupervisedGraphClassification(\n",
    "        layer_sizes=[64, 64],\n",
    "        activations=[\"relu\", \"relu\"],\n",
    "        generator=generator,\n",
    "        dropout=0.5,\n",
    "    )\n",
    "    x_inp, x_out = gc_model.in_out_tensors()\n",
    "    predictions = Dense(units=32, activation=\"relu\")(x_out)\n",
    "    predictions = Dense(units=16, activation=\"relu\")(predictions)\n",
    "    predictions = Dense(units=1, activation=\"sigmoid\")(predictions)\n",
    "\n",
    "    # Let's create the Keras model and prepare it for training\n",
    "    model = Model(inputs=x_inp, outputs=predictions)\n",
    "    model.compile(optimizer=Adam(0.005), loss=binary_crossentropy, metrics=[\"acc\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "We can now train the model using the model's `fit` method. First, we specify some important training parameters such as the number of training epochs, number of fold for cross validation and the number of time to repeat cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 200  # maximum number of training epochs\n",
    "folds = 10  # the number of folds for k-fold cross validation\n",
    "n_repeats = 5  # the number of repeats for repeated k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=0, patience=25, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `train_fold` is used to train a graph classification model for a single fold of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(model, train_gen, test_gen, es, epochs):\n",
    "    history = model.fit(\n",
    "        train_gen, epochs=epochs, validation_data=test_gen, verbose=0, callbacks=[es],\n",
    "    )\n",
    "    # calculate performance on the test data and return along with history\n",
    "    test_metrics = model.evaluate(test_gen, verbose=0)\n",
    "    test_acc = test_metrics[model.metrics_names.index(\"acc\")]\n",
    "\n",
    "    return history, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generators(train_index, test_index, graph_labels, batch_size):\n",
    "    train_gen = generator.flow(\n",
    "        train_index, targets=graph_labels.iloc[train_index].values, batch_size=batch_size\n",
    "    )\n",
    "    test_gen = generator.flow(\n",
    "        test_index, targets=graph_labels.iloc[test_index].values, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return train_gen, test_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below puts all the above functionality together in a training loop for repeated k-fold cross-validation where the number of folds is 10, `folds=10`; that is we do 10-fold cross validation `n_repeats` times where `n_repeats=5`.\n",
    "\n",
    "**Note**: The below code may take a long time to run depending on the value set for `n_repeats`. The larger the latter, the longer it takes since for each repeat we train and evaluate 10 graph classification models, one for each fold of the data. For progress updates, we recommend that you set `verbose=2` in the call to the `fit` method is cell 10, line 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating on fold 1 out of 50...\n",
      "Training and evaluating on fold 2 out of 50...\n",
      "Training and evaluating on fold 3 out of 50...\n",
      "Training and evaluating on fold 4 out of 50...\n",
      "Training and evaluating on fold 5 out of 50...\n",
      "Training and evaluating on fold 6 out of 50...\n",
      "Training and evaluating on fold 7 out of 50...\n",
      "Training and evaluating on fold 8 out of 50...\n",
      "Training and evaluating on fold 9 out of 50...\n",
      "Training and evaluating on fold 10 out of 50...\n",
      "Training and evaluating on fold 11 out of 50...\n",
      "Training and evaluating on fold 12 out of 50...\n",
      "Training and evaluating on fold 13 out of 50...\n",
      "Training and evaluating on fold 14 out of 50...\n",
      "Training and evaluating on fold 15 out of 50...\n",
      "Training and evaluating on fold 16 out of 50...\n",
      "Training and evaluating on fold 17 out of 50...\n",
      "Training and evaluating on fold 18 out of 50...\n",
      "Training and evaluating on fold 19 out of 50...\n",
      "Training and evaluating on fold 20 out of 50...\n",
      "Training and evaluating on fold 21 out of 50...\n",
      "Training and evaluating on fold 22 out of 50...\n",
      "Training and evaluating on fold 23 out of 50...\n",
      "Training and evaluating on fold 24 out of 50...\n",
      "Training and evaluating on fold 25 out of 50...\n",
      "Training and evaluating on fold 26 out of 50...\n",
      "Training and evaluating on fold 27 out of 50...\n",
      "Training and evaluating on fold 28 out of 50...\n",
      "Training and evaluating on fold 29 out of 50...\n",
      "Training and evaluating on fold 30 out of 50...\n",
      "Training and evaluating on fold 31 out of 50...\n",
      "Training and evaluating on fold 32 out of 50...\n",
      "Training and evaluating on fold 33 out of 50...\n",
      "Training and evaluating on fold 34 out of 50...\n",
      "Training and evaluating on fold 35 out of 50...\n",
      "Training and evaluating on fold 36 out of 50...\n",
      "Training and evaluating on fold 37 out of 50...\n",
      "Training and evaluating on fold 38 out of 50...\n",
      "Training and evaluating on fold 39 out of 50...\n",
      "Training and evaluating on fold 40 out of 50...\n",
      "Training and evaluating on fold 41 out of 50...\n",
      "Training and evaluating on fold 42 out of 50...\n",
      "Training and evaluating on fold 43 out of 50...\n",
      "Training and evaluating on fold 44 out of 50...\n",
      "Training and evaluating on fold 45 out of 50...\n",
      "Training and evaluating on fold 46 out of 50...\n",
      "Training and evaluating on fold 47 out of 50...\n",
      "Training and evaluating on fold 48 out of 50...\n",
      "Training and evaluating on fold 49 out of 50...\n",
      "Training and evaluating on fold 50 out of 50...\n"
     ]
    }
   ],
   "source": [
    "test_accs = []\n",
    "\n",
    "stratified_folds = model_selection.RepeatedStratifiedKFold(\n",
    "    n_splits=folds, n_repeats=n_repeats\n",
    ").split(graph_labels, graph_labels)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(stratified_folds):\n",
    "    print(f\"Training and evaluating on fold {i+1} out of {folds * n_repeats}...\")\n",
    "    train_gen, test_gen = get_generators(\n",
    "        train_index, test_index, graph_labels, batch_size=30\n",
    "    )\n",
    "\n",
    "    model = create_graph_classification_model(generator)\n",
    "\n",
    "    history, acc = train_fold(model, train_gen, test_gen, es, epochs)\n",
    "\n",
    "    test_accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over all folds mean: 75.6% and std: 7.4%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Accuracy over all folds mean: {np.mean(test_accs)*100:.3}% and std: {np.std(test_accs)*100:.2}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we plot a histogram of the accuracy of all `n_repeats x folds` models trained (50 in total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(test_accs)\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shown above indicates the difficulty of training a good model on the MUTAG dataset due to the following factors,\n",
    "- small amount of available data, i.e., only 188 graphs\n",
    "- small amount of validation data since for a single fold only 19 graphs are used for validation\n",
    "- the data are unbalanced since the majority class is twice as prevalent in the data\n",
    "\n",
    "Given the above, average performance as estimated using repeated 10-fold cross validation displays high variance but overall good performance for a straightforward application of graph convolutional neural networks to supervised graph classification. The high variance is likely the result of the small dataset size.\n",
    "\n",
    "Generally, performance is a bit lower than SOTA in recent literature. However, we have not tuned the model for the best performance possible so some improvement over the current baseline may be attainable.\n",
    "\n",
    "When comparing to graph kernel-based approaches, our straightforward GCN with mean pooling graph classification model is competitive with the WL kernel being the exception.\n",
    "\n",
    "For comparison, some performance numbers repeated from [3] for graph kernel-based approaches are, \n",
    "- Graphlet Kernel (GK): $81.39\\pm1.74$\n",
    "- Random Walk Kernel (RW): $79.17\\pm2.07$\n",
    "- Propagation Kernel (PK): $76.00\\pm2.69$\n",
    "- Weisfeiler-Lehman Subtree Kernel (WL): $84.11\\pm1.91$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "CloudRunner"
    ]
   },
   "source": [
    "<table><tr><td>Run the latest release of this notebook:</td><td><a href=\"https://mybinder.org/v2/gh/stellargraph/stellargraph/master?urlpath=lab/tree/demos/graph-classification/gcn-supervised-graph-classification.ipynb\" alt=\"Open In Binder\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\"/></a></td><td><a href=\"https://colab.research.google.com/github/stellargraph/stellargraph/blob/master/demos/graph-classification/gcn-supervised-graph-classification.ipynb\" alt=\"Open In Colab\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a></td></tr></table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
